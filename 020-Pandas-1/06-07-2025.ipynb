{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157c7f6b",
   "metadata": {},
   "source": [
    "# Pandas-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas uses numpy internally. The numpy, as we learned, is for scientific computing. \n",
    "\n",
    "# Pandas is open source library, used for data manipulation and analysis.\n",
    "\n",
    "\n",
    "\n",
    "# Why Pandas? While Python lists, dictionaries, and NumPy arrays are excellent foundational tools,\n",
    "# ==================================================================================================================== \n",
    "# Pandas builds upon them to provide higher-level, more structured, and more convenient data manipulation capabilities, \n",
    "# especially for tabular (spreadsheet-like) data\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Here's a breakdown of why Pandas is preferred:\n",
    "\n",
    "1. Handling Tabular Data Naturally (DataFrames and Series)\n",
    "Python Lists/Dicts: Great for general-purpose collections. Lists are ordered sequences, and dictionaries are key-value pairs. They don't inherently represent columns and rows with labels in a consistent way for analysis.\n",
    "\n",
    "NumPy Arrays: Fantastic for numerical operations on homogeneous data. They are powerful matrices. However:\n",
    "\n",
    "They are primarily for numerical data (homogeneous dtype). If you have mixed data types (numbers, strings, dates), NumPy arrays struggle or force dtype=object, losing performance benefits.\n",
    "They lack named columns and rows (labels). You refer to data by integer indices (array[0, 1]). This makes code harder to read, maintain, and debug when dealing with complex datasets.\n",
    "They don't directly handle missing data (NaN values) as gracefully for mixed types.\n",
    "Pandas (DataFrame & Series):\n",
    "\n",
    "DataFrame: The core Pandas object, designed explicitly for tabular data. It's essentially a collection of Series (columns) that share a common index (rows). It has: \n",
    "\n",
    "Labeled Axes: Both rows (index) and columns have names, making data selection and understanding intuitive (df['column_name'], df.loc['row_label']).\n",
    "Heterogeneous Data Types: Each column can have its own dtype (e.g., one column of integers, another of strings, a third of booleans), while still being highly efficient.\n",
    "Built-in Missing Data Handling: NaN (Not a Number) is natively supported and Pandas provides powerful methods to fillna(), dropna(), etc.\n",
    "2. Convenience and Expressiveness\n",
    "Python/NumPy: Often requires more verbose code or multiple steps for common data tasks. For example, filtering a NumPy array based on conditions across multiple columns, or joining data from different sources.\n",
    "Pandas: Provides highly expressive, concise, and intuitive methods for common data operations:\n",
    "Filtering/Subsetting: df[df['age'] > 30] is much more readable than equivalent NumPy boolean indexing on multiple arrays.\n",
    "Grouping and Aggregation (.groupby()): Incredibly powerful for summarizing data by categories (e.g., \"average sales per region\"). This is complex and verbose with just NumPy.\n",
    "Merging/Joining (.merge(), .join()): SQL-like operations to combine DataFrames based on common columns, essential for integrating data from various sources.\n",
    "Reshaping (.pivot_table(), .stack(), .unstack()): Easily transform the layout of your data for different analytical needs.\n",
    "Time Series Functionality: Robust features for handling dates and times, resampling, rolling calculations, etc., which are crucial for time-series analysis.\n",
    "3. Missing Data Handling\n",
    "NumPy: NaN (Not a Number) is the standard for missing numerical data. However, for non-numeric data types, NumPy arrays might fallback to dtype=object which can be less efficient and harder to work with. Operations involving NaN in NumPy require explicit handling.\n",
    "Pandas: Integrates NaN seamlessly across all data types (using object dtype for strings with NaNs, Nullable Dtype for integers, etc.). It provides dedicated methods like .isnull(), .notnull(), .dropna(), .fillna(), and .interpolate() that make dealing with missing values much simpler and more robust.\n",
    "4. Integration with Data Sources\n",
    "Python/NumPy: You'd typically need to write custom code or use other libraries to read CSV, Excel, SQL databases, JSON, etc., and then convert them into arrays/lists.\n",
    "Pandas: Built-in I/O tools make reading and writing various data formats trivial (pd.read_csv(), pd.read_excel(), df.to_sql(), df.to_json(), etc.). This dramatically speeds up the data loading and saving process.\n",
    "5. Performance (Built on NumPy)\n",
    "Crucially, Pandas is built on top of NumPy. This means that underneath its user-friendly interface, many Pandas operations leverage NumPy's optimized, vectorized C implementations. So, you get the best of both worlds: high-level convenience and low-level performance.\n",
    "\n",
    "When to Use What:\n",
    "#==============================#\n",
    "Basic Python (lists, dicts, tuples): For general-purpose programming, small, unstructured collections, or when you need highly custom data structures.\n",
    "NumPy Arrays: For pure numerical computation, especially when dealing with large, homogeneous, multi-dimensional arrays (like images, scientific simulations, numerical linear algebra). If you're doing complex math on number grids, NumPy is your direct tool.\n",
    "Pandas DataFrames/Series: For most data analysis tasks, especially with tabular data that is mixed-type, has labels, or contains missing values. It's the go-to for data cleaning, exploration, transformation, and preparation before feeding it into machine learning models.\n",
    "In summary, while you could theoretically do everything with just Python and NumPy, Pandas provides a specialized, highly optimized, and incredibly convenient framework that abstracts away much of the complexity, making data analysis much faster, easier, and more enjoyable for real-world datasets.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00965f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\byju\\dropbox\\kna\\udsgai\\venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\byju\\dropbox\\kna\\udsgai\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\byju\\dropbox\\kna\\udsgai\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.0 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.8/11.0 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 16.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "# install pandas and import\n",
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8b255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c5ecf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4b05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Series s1 ---\n",
      "0    85\n",
      "1    92\n",
      "2    78\n",
      "3    65\n",
      "4    90\n",
      "dtype: int64\n",
      "\n",
      "Type of s1: <class 'pandas.core.series.Series'>\n",
      "Index of s1: RangeIndex(start=0, stop=5, step=1)\n",
      "Values of s1: [85 92 78 65 90]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the scores for s1\n",
    "scores_s1 = [85, 92, 78, 65, 90]\n",
    "\n",
    "# Create the Series s1\n",
    "s1 = pd.Series(scores_s1)\n",
    "\n",
    "print(\"--- Series s1 ---\")\n",
    "print(s1)\n",
    "print(f\"\\nType of s1: {type(s1)}\")\n",
    "print(f\"Index of s1: {s1.index}\")\n",
    "print(f\"Values of s1: {s1.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00abe9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Series s2 ---\n",
      "Alice      75\n",
      "Bob        88\n",
      "Charlie    95\n",
      "David      80\n",
      "Name: scores, dtype: int64\n",
      "\n",
      "Type of s2: <class 'pandas.core.series.Series'>\n",
      "Index of s2: Index(['Alice', 'Bob', 'Charlie', 'David'], dtype='object')\n",
      "Values of s2: [75 88 95 80]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the scores for s2\n",
    "scores_s2 = [75, 88, 95, 80]\n",
    "\n",
    "# Define the custom index labels (names)\n",
    "names_index = ['Alice', 'Bob', 'Charlie', 'David']\n",
    "\n",
    "# Create the Series s2 with a custom index\n",
    "s2 = pd.Series(scores_s2, index=names_index, name =\"scores\")\n",
    "\n",
    "print(\"\\n--- Series s2 ---\")\n",
    "print(s2)\n",
    "print(f\"\\nType of s2: {type(s2)}\")\n",
    "print(f\"Index of s2: {s2.index}\")\n",
    "print(f\"Values of s2: {s2.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56992d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Series created from a Dictionary ---\n",
      "Math       95\n",
      "Science    88\n",
      "History    72\n",
      "Art        91\n",
      "English    85\n",
      "dtype: int64\n",
      "\n",
      "Type of s_from_dict: <class 'pandas.core.series.Series'>\n",
      "Index of s_from_dict: Index(['Math', 'Science', 'History', 'Art', 'English'], dtype='object')\n",
      "Values of s_from_dict: [95 88 72 91 85]\n",
      "Data type (dtype) of s_from_dict: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating series from dictionary\n",
    "\n",
    "'''\n",
    "Creating a Pandas Series from a Python dictionary is a very common and convenient way to initialize a Series,\n",
    "especially when you want specific labels (keys from the dictionary) to be directly associated with values.\n",
    "\n",
    "When you create a Series from a dictionary:\n",
    "\n",
    "The keys of the dictionary become the index labels of the Series.\n",
    "The values of the dictionary become the data values in the Series.\n",
    "Here's an example:\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define a Python dictionary\n",
    "# Keys will be the index labels, values will be the data\n",
    "data_dict = {\n",
    "    'Math': 95,\n",
    "    'Science': 88,\n",
    "    'History': 72,\n",
    "    'Art': 91,\n",
    "    'English': 85\n",
    "}\n",
    "\n",
    "# Create a Pandas Series from the dictionary\n",
    "s_from_dict = pd.Series(data_dict)\n",
    "\n",
    "print(\"--- Series created from a Dictionary ---\")\n",
    "print(s_from_dict)\n",
    "print(f\"\\nType of s_from_dict: {type(s_from_dict)}\")\n",
    "print(f\"Index of s_from_dict: {s_from_dict.index}\")\n",
    "print(f\"Values of s_from_dict: {s_from_dict.values}\")\n",
    "print(f\"Data type (dtype) of s_from_dict: {s_from_dict.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f2795",
   "metadata": {},
   "source": [
    "# Series Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18006d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Series (exam_scores) ---\n",
      "Alice      85\n",
      "Bob        92\n",
      "Charlie    78\n",
      "David      65\n",
      "Eve        90\n",
      "Frank      72\n",
      "Grace      88\n",
      "dtype: int64\n",
      "Data type (dtype): int64\n",
      "------------------------------\n",
      "\n",
      "--- Indexing by Label ---\n",
      "Score for Alice: 85\n",
      "\n",
      "Scores for Bob, Eve, Grace:\n",
      " Bob      92\n",
      "Eve      90\n",
      "Grace    88\n",
      "dtype: int64\n",
      "\n",
      "Error accessing non-existent label: 'Zoe'\n",
      "\n",
      "--- Slicing by Label ---\n",
      "\n",
      "Scores from Charlie to Eve (inclusive):\n",
      " Charlie    78\n",
      "David      65\n",
      "Eve        90\n",
      "dtype: int64\n",
      "\n",
      "Scores from David to end:\n",
      " David    65\n",
      "Eve      90\n",
      "Frank    72\n",
      "Grace    88\n",
      "dtype: int64\n",
      "\n",
      "Scores from beginning to Charlie:\n",
      " Alice      85\n",
      "Bob        92\n",
      "Charlie    78\n",
      "dtype: int64\n",
      "\n",
      "--- Indexing by Position (.iloc[]) ---\n",
      "Score at position 0: 85\n",
      "\n",
      "Scores at positions 1, 4, 6:\n",
      " Bob      92\n",
      "Eve      90\n",
      "Grace    88\n",
      "dtype: int64\n",
      "\n",
      "Error accessing out-of-bounds position: single positional indexer is out-of-bounds\n",
      "\n",
      "--- Slicing by Position (.iloc[]) ---\n",
      "\n",
      "Scores from position 1 to 4 (exclusive of 4):\n",
      " Bob        92\n",
      "Charlie    78\n",
      "David      65\n",
      "dtype: int64\n",
      "\n",
      "Scores from position 2 to end:\n",
      " Charlie    78\n",
      "David      65\n",
      "Eve        90\n",
      "Frank      72\n",
      "Grace      88\n",
      "dtype: int64\n",
      "\n",
      "Scores from beginning to position 3 (exclusive of 3):\n",
      " Alice      85\n",
      "Bob        92\n",
      "Charlie    78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Series created from a dictionary with int64 values and explore how to perform slicing and indexing on it.\n",
    "\n",
    "When you create a Series from a dictionary, the index becomes the dictionary's keys, \n",
    "and you can then use these labels for indexing, as well as integer-based positional indexing \n",
    "(though it's generally best to stick to label-based if you have explicit labels to avoid ambiguity).\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series from a dictionary with int64 values\n",
    "# Pandas will automatically infer the dtype as int64 because all values are integers.\n",
    "exam_scores = pd.Series({\n",
    "    'Alice': 85,\n",
    "    'Bob': 92,\n",
    "    'Charlie': 78,\n",
    "    'David': 65,\n",
    "    'Eve': 90,\n",
    "    'Frank': 72,\n",
    "    'Grace': 88\n",
    "})\n",
    "\n",
    "print(\"--- Original Series (exam_scores) ---\")\n",
    "print(exam_scores)\n",
    "print(f\"Data type (dtype): {exam_scores.dtype}\") # Should be int64\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 1. Indexing by Label ---\n",
    "print(\"\\n--- Indexing by Label ---\")\n",
    "\n",
    "# Accessing a single element by its label\n",
    "print(f\"Score for Alice: {exam_scores['Alice']}\")\n",
    "\n",
    "# Accessing multiple elements by a list of labels (Fancy Indexing)\n",
    "selected_students = exam_scores[['Bob', 'Eve', 'Grace']]\n",
    "print(\"\\nScores for Bob, Eve, Grace:\\n\", selected_students)\n",
    "\n",
    "# Attempting to access a non-existent label will raise a KeyError\n",
    "try:\n",
    "    print(exam_scores['Zoe'])\n",
    "except KeyError as e:\n",
    "    print(f\"\\nError accessing non-existent label: {e}\")\n",
    "\n",
    "# --- 2. Slicing by Label ---\n",
    "# Slicing with labels is INCLUSIVE of the end label!\n",
    "print(\"\\n--- Slicing by Label ---\")\n",
    "\n",
    "# Scores from Charlie to Eve (inclusive)\n",
    "scores_slice_label = exam_scores['Charlie':'Eve']\n",
    "print(\"\\nScores from Charlie to Eve (inclusive):\\n\", scores_slice_label)\n",
    "\n",
    "# Slicing from a specific label to the end\n",
    "scores_from_david = exam_scores['David':]\n",
    "print(\"\\nScores from David to end:\\n\", scores_from_david)\n",
    "\n",
    "# Slicing from the beginning to a specific label\n",
    "scores_to_charlie = exam_scores[:'Charlie']\n",
    "print(\"\\nScores from beginning to Charlie:\\n\", scores_to_charlie)\n",
    "\n",
    "\n",
    "# --- 3. Indexing by Position (Integer Location) ---\n",
    "# Use .iloc[] for purely integer-location based indexing\n",
    "print(\"\\n--- Indexing by Position (.iloc[]) ---\")\n",
    "\n",
    "# Accessing a single element by its integer position (0-indexed)\n",
    "print(f\"Score at position 0: {exam_scores.iloc[0]}\") # Alice's score\n",
    "\n",
    "# Accessing multiple elements by a list of integer positions\n",
    "selected_by_pos = exam_scores.iloc[[1, 4, 6]] # Bob, Eve, Grace\n",
    "print(\"\\nScores at positions 1, 4, 6:\\n\", selected_by_pos)\n",
    "\n",
    "# Attempting to access an out-of-bounds position will raise an IndexError\n",
    "try:\n",
    "    print(exam_scores.iloc[10])\n",
    "except IndexError as e:\n",
    "    print(f\"\\nError accessing out-of-bounds position: {e}\")\n",
    "\n",
    "# --- 4. Slicing by Position (Integer Location) ---\n",
    "# Use .iloc[] for purely integer-location based slicing\n",
    "# Slicing with .iloc[] is EXCLUSIVE of the end position, just like Python lists\n",
    "print(\"\\n--- Slicing by Position (.iloc[]) ---\")\n",
    "\n",
    "# Scores from position 1 to 4 (exclusive of 4) -> index 1, 2, 3 (Bob, Charlie, David)\n",
    "scores_slice_pos = exam_scores.iloc[1:4]\n",
    "print(\"\\nScores from position 1 to 4 (exclusive of 4):\\n\", scores_slice_pos)\n",
    "\n",
    "# Scores from position 2 to end\n",
    "scores_from_pos_2 = exam_scores.iloc[2:]\n",
    "print(\"\\nScores from position 2 to end:\\n\", scores_from_pos_2)\n",
    "\n",
    "# Scores from beginning to position 3 (exclusive of 3)\n",
    "scores_to_pos_3 = exam_scores.iloc[:3]\n",
    "print(\"\\nScores from beginning to position 3 (exclusive of 3):\\n\", scores_to_pos_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb0c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nKey Points to Remember:\\n\\nLabel-based indexing (exam_scores['label'] or exam_scores[['label1', 'label2']]): Best when you know the specific labels you want.\\nLabel-based slicing (exam_scores['start_label':'end_label']): Inclusive of the end_label.\\nPositional indexing (exam_scores.iloc[position] or exam_scores.iloc[[pos1, pos2]]): Best when you need to access by integer location, similar to Python lists.\\nPositional slicing (exam_scores.iloc[start_pos:end_pos]): Exclusive of the end_pos, just like Python list slicing.\\nUsing the appropriate indexing method (.loc for labels, .iloc for positions) improves clarity and avoids potential ambiguity, especially when your index labels happen to be integers themselves.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Key Points to Remember:\n",
    "\n",
    "Label-based indexing (exam_scores['label'] or exam_scores[['label1', 'label2']]): Best when you know the specific labels you want.\n",
    "Label-based slicing (exam_scores['start_label':'end_label']): Inclusive of the end_label.\n",
    "Positional indexing (exam_scores.iloc[position] or exam_scores.iloc[[pos1, pos2]]): Best when you need to access by integer location, similar to Python lists.\n",
    "Positional slicing (exam_scores.iloc[start_pos:end_pos]): Exclusive of the end_pos, just like Python list slicing.\n",
    "Using the appropriate indexing method (.loc for labels, .iloc for positions) improves clarity and avoids potential ambiguity, especially when your index labels happen to be integers themselves.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8adfb",
   "metadata": {},
   "source": [
    "# Difference between loc and iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b44a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In Pandas, loc and iloc are two of the most fundamental and frequently used indexers for selecting data from Series and DataFrames.\n",
    "They are distinct in how they interpret the \"selection\" you provide:\n",
    "\n",
    "loc is primarily label-based: It selects data by the labels of rows and columns.\n",
    "iloc is primarily integer-location based: It selects data by the position (integer index) of rows and columns.\n",
    "Let's break them down with examples using both a Series and a DataFrame.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Series 's' ---\n",
      "apple         100\n",
      "banana        200\n",
      "cherry        300\n",
      "date          400\n",
      "elderberry    500\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "--- Using .loc (Label-based) ---\n",
      "s.loc['banana']: 200\n",
      "\n",
      "s.loc[['apple', 'date']]:\n",
      "apple    100\n",
      "date     400\n",
      "dtype: int64\n",
      "\n",
      "s.loc['banana':'date']:\n",
      "banana    200\n",
      "cherry    300\n",
      "date      400\n",
      "dtype: int64\n",
      "\n",
      "--- Using .iloc (Integer-location based) ---\n",
      "s.iloc[1]: 200\n",
      "\n",
      "s.iloc[[0, 3]]:\n",
      "apple    100\n",
      "date     400\n",
      "dtype: int64\n",
      "\n",
      "s.iloc[1:4]:\n",
      "banana    200\n",
      "cherry    300\n",
      "date      400\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Pandas Series: loc vs. iloc\n",
    "#===================================\n",
    "\n",
    "We'll start with a Series where the index labels are distinct from their integer positions to highlight the difference.\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with custom, non-numeric labels\n",
    "s = pd.Series([100, 200, 300, 400, 500],\n",
    "              index=['apple', 'banana', 'cherry', 'date', 'elderberry'])\n",
    "\n",
    "print(\"--- Original Series 's' ---\")\n",
    "print(s)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Using .loc (Label-based) ---\n",
    "print(\"\\n--- Using .loc (Label-based) ---\")\n",
    "\n",
    "# 1. Select a single element by label\n",
    "print(f\"s.loc['banana']: {s.loc['banana']}\")\n",
    "\n",
    "# 2. Select multiple elements by a list of labels (Fancy Indexing)\n",
    "print(f\"\\ns.loc[['apple', 'date']]:\\n{s.loc[['apple', 'date']]}\")\n",
    "\n",
    "# 3. Slice by label (INCLUSIVE of the end label)\n",
    "# Selects elements from 'banana' up to and including 'date'\n",
    "print(f\"\\ns.loc['banana':'date']:\\n{s.loc['banana':'date']}\")\n",
    "\n",
    "# --- Using .iloc (Integer-location based) ---\n",
    "print(\"\\n--- Using .iloc (Integer-location based) ---\")\n",
    "\n",
    "# 1. Select a single element by integer position (0-indexed)\n",
    "print(f\"s.iloc[1]: {s.iloc[1]}\") # This selects the element at position 1 (which is 'banana')\n",
    "\n",
    "# 2. Select multiple elements by a list of integer positions (Fancy Indexing)\n",
    "print(f\"\\ns.iloc[[0, 3]]:\\n{s.iloc[[0, 3]]}\") # Selects elements at positions 0 ('apple') and 3 ('date')\n",
    "\n",
    "# 3. Slice by integer position (EXCLUSIVE of the end position, like Python lists)\n",
    "# Selects elements from position 1 up to (but not including) position 4\n",
    "# This selects elements at positions 1, 2, 3 ('banana', 'cherry', 'date')\n",
    "print(f\"\\ns.iloc[1:4]:\\n{s.iloc[1:4]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c33c5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame 'df' ---\n",
      "      Name  Age City  Score\n",
      "a    Alice   24   NY     85\n",
      "b      Bob   27   LA     92\n",
      "c  Charlie   22   SF     78\n",
      "d    David   32   NY     65\n",
      "e      Eve   29   SF     90\n",
      "------------------------------\n",
      "\n",
      "--- Using .loc ---\n",
      "\n",
      "df.loc['c']:\n",
      "Name     Charlie\n",
      "Age           22\n",
      "City          SF\n",
      "Score         78\n",
      "Name: c, dtype: object\n",
      "\n",
      "df.loc[['a', 'd'], ['Name', 'Score']]:\n",
      "    Name  Score\n",
      "a  Alice     85\n",
      "d  David     65\n",
      "\n",
      "df.loc['b':'d', :]:\n",
      "      Name  Age City  Score\n",
      "b      Bob   27   LA     92\n",
      "c  Charlie   22   SF     78\n",
      "d    David   32   NY     65\n",
      "\n",
      "df.loc[:, 'Age':'Score']:\n",
      "   Age City  Score\n",
      "a   24   NY     85\n",
      "b   27   LA     92\n",
      "c   22   SF     78\n",
      "d   32   NY     65\n",
      "e   29   SF     90\n",
      "\n",
      "df.loc[df['Age'] > 25, ['Name', 'City']]:\n",
      "    Name City\n",
      "b    Bob   LA\n",
      "d  David   NY\n",
      "e    Eve   SF\n",
      "\n",
      "--- Using .iloc ---\n",
      "\n",
      "df.iloc[2]:\n",
      "Name     Charlie\n",
      "Age           22\n",
      "City          SF\n",
      "Score         78\n",
      "Name: c, dtype: object\n",
      "\n",
      "df.iloc[[0, 3], [0, 3]]:\n",
      "    Name  Score\n",
      "a  Alice     85\n",
      "d  David     65\n",
      "\n",
      "df.iloc[1:4, :]:\n",
      "      Name  Age City  Score\n",
      "b      Bob   27   LA     92\n",
      "c  Charlie   22   SF     78\n",
      "d    David   32   NY     65\n",
      "\n",
      "df.iloc[:, 1:3]:\n",
      "   Age City\n",
      "a   24   NY\n",
      "b   27   LA\n",
      "c   22   SF\n",
      "d   32   NY\n",
      "e   29   SF\n",
      "\n",
      "df.iloc[(df['Age'] > 25).values, :2]:\n",
      "    Name  Age\n",
      "b    Bob   27\n",
      "d  David   32\n",
      "e    Eve   29\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Pandas DataFrame: loc vs. iloc\n",
    "#=======================================\n",
    "\n",
    "For DataFrames, loc and iloc extend to both rows and columns. \n",
    "Their general syntax is df.loc[row_selector, column_selector] and df.iloc[row_selector, column_selector].\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [24, 27, 22, 32, 29],\n",
    "    'City': ['NY', 'LA', 'SF', 'NY', 'SF'],\n",
    "    'Score': [85, 92, 78, 65, 90]\n",
    "}\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "print(\"--- Original DataFrame 'df' ---\")\n",
    "print(df)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Using .loc (Label-based for rows and columns) ---\n",
    "print(\"\\n--- Using .loc ---\")\n",
    "\n",
    "# 1. Select a single row by its label\n",
    "print(f\"\\ndf.loc['c']:\\n{df.loc['c']}\")\n",
    "\n",
    "# 2. Select specific rows and specific columns by labels\n",
    "print(f\"\\ndf.loc[['a', 'd'], ['Name', 'Score']]:\\n{df.loc[['a', 'd'], ['Name', 'Score']]}\")\n",
    "\n",
    "# 3. Slice rows by labels (inclusive) and select all columns\n",
    "print(f\"\\ndf.loc['b':'d', :]:\\n{df.loc['b':'d', :]}\")\n",
    "\n",
    "# 4. Select all rows and slice columns by labels (inclusive)\n",
    "print(f\"\\ndf.loc[:, 'Age':'Score']:\\n{df.loc[:, 'Age':'Score']}\")\n",
    "\n",
    "# 5. Boolean indexing with .loc (very common!)\n",
    "# Select rows where Age > 25 and only show Name and City columns\n",
    "print(f\"\\ndf.loc[df['Age'] > 25, ['Name', 'City']]:\\n{df.loc[df['Age'] > 25, ['Name', 'City']]}\")\n",
    "\n",
    "# --- Using .iloc (Integer-location based for rows and columns) ---\n",
    "print(\"\\n--- Using .iloc ---\")\n",
    "\n",
    "# 1. Select a single row by its integer position\n",
    "print(f\"\\ndf.iloc[2]:\\n{df.iloc[2]}\") # Corresponds to row with label 'c'\n",
    "\n",
    "# 2. Select specific rows and specific columns by integer positions\n",
    "print(f\"\\ndf.iloc[[0, 3], [0, 3]]:\\n{df.iloc[[0, 3], [0, 3]]}\") # (row 0, row 3) and (col 0, col 3)\n",
    "\n",
    "# 3. Slice rows by integer positions (exclusive) and select all columns\n",
    "print(f\"\\ndf.iloc[1:4, :]:\\n{df.iloc[1:4, :]}\") # Rows at pos 1, 2, 3 (labels 'b', 'c', 'd')\n",
    "\n",
    "# 4. Select all rows and slice columns by integer positions (exclusive)\n",
    "print(f\"\\ndf.iloc[:, 1:3]:\\n{df.iloc[:, 1:3]}\") # Columns at pos 1, 2 ('Age', 'City')\n",
    "\n",
    "# 5. Using boolean indexing with .iloc (less common, usually loc is clearer for this)\n",
    "# You'd typically use .loc for boolean masks as the mask is label-aligned\n",
    "# Example: Select rows where Age > 25 and only show first two columns\n",
    "print(f\"\\ndf.iloc[(df['Age'] > 25).values, :2]:\\n{df.iloc[(df['Age'] > 25).values, :2]}\")\n",
    "# Note: (df['Age'] > 25).values converts the Series of booleans to a NumPy array of booleans,\n",
    "# which .iloc can accept for row selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855a6af",
   "metadata": {},
   "source": [
    "# When to use loc vs. iloc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9f1be9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nloc:\\n\\nAlways prefer loc when you know the row and column labels. It makes your code more readable and robust to changes in data order (e.g., if a new row is inserted, the integer position changes but the label stays the same).\\nEssential for boolean indexing (e.g., df.loc[df['column'] > value]).\\niloc:\\n\\nUse iloc when you need to select rows/columns purely by their positional order, regardless of their labels.\\nUseful in loops or when writing functions where you iterate through positions.\\nCrucial Distinction for Slicing:\\n\\nloc slicing: The end label is inclusive. df.loc['start':'end'] includes 'end'.\\niloc slicing: The end position is exclusive. df.iloc[start:end] does not include end. (This is consistent with standard Python list slicing).\\nMastering loc and iloc is fundamental for effective data manipulation and analysis in Pandas.\\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "loc:\n",
    "\n",
    "Always prefer loc when you know the row and column labels. It makes your code more readable and robust to changes in data order (e.g., if a new row is inserted, the integer position changes but the label stays the same).\n",
    "Essential for boolean indexing (e.g., df.loc[df['column'] > value]).\n",
    "iloc:\n",
    "\n",
    "Use iloc when you need to select rows/columns purely by their positional order, regardless of their labels.\n",
    "Useful in loops or when writing functions where you iterate through positions.\n",
    "Crucial Distinction for Slicing:\n",
    "\n",
    "loc slicing: The end label is inclusive. df.loc['start':'end'] includes 'end'.\n",
    "iloc slicing: The end position is exclusive. df.iloc[start:end] does not include end. (This is consistent with standard Python list slicing).\n",
    "Mastering loc and iloc is fundamental for effective data manipulation and analysis in Pandas.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note again: While slicing with \n",
    "\n",
    "# .loc[start, end] end position is inclusive\n",
    "# .iloc[start, end] end position is exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fef9d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can come in different formats:\n",
    "# csv (Comma Seperated Values)\n",
    "# json (Java Script Object Notation)\n",
    "# xml (Extensive Markup Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "\n",
    "'''\n",
    "Let's define JSON-like datasets in Python, demonstrating how to structure them to represent two individuals with \"name\" and \"age\" fields, first as a list of dictionaries (implicitly indexed 0, 1) and then as a dictionary where \"data\" is a key holding that list.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5926c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- JSON Data (List of Dictionaries) ---\n",
      "[\n",
      "    {\n",
      "        \"name\": \"Alice\",\n",
      "        \"age\": 30\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Bob\",\n",
      "        \"age\": 24\n",
      "    }\n",
      "]\n",
      "\n",
      "This structure implicitly has index 0 and 1 for the two records.\n"
     ]
    }
   ],
   "source": [
    "'''Method 1: List of Dictionaries (Implicit Index 0, 1)\n",
    "#============================================================\n",
    "\n",
    "This is the most common and natural way to represent a collection of structured records in JSON. Each record is a dictionary, and the overall structure is a list of these dictionaries. When you load this into Pandas, it will automatically get a default integer index (0, 1, ...).\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "# List of dictionaries, where each dictionary represents a record\n",
    "json_data_list = [\n",
    "    {\n",
    "        \"name\": \"Alice\",\n",
    "        \"age\": 30\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"age\": 24\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"--- JSON Data (List of Dictionaries) ---\")\n",
    "# Using json.dumps for pretty printing in Python, looks like a standard JSON array\n",
    "print(json.dumps(json_data_list, indent=4))\n",
    "print(\"\\nThis structure implicitly has index 0 and 1 for the two records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b846693",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53031cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- JSON Data (Dictionary with 'data' key) ---\n",
      "{\n",
      "    \"metadata\": {\n",
      "        \"source\": \"example_data\",\n",
      "        \"version\": \"1.0\"\n",
      "    },\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"name\": \"Charlie\",\n",
      "            \"age\": 35\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Diana\",\n",
      "            \"age\": 28\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Here, the list of records is accessed via the 'data' key.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Method 2: Dictionary with \"data\" as Index (Key)\n",
    "#==================================================\n",
    "\n",
    "Here, we wrap the list of dictionaries inside another dictionary, where \"data\" is the key pointing to that list. This is useful if you have metadata alongside your main data array in the JSON.\n",
    "'''\n",
    "\n",
    "import json\n",
    "\n",
    "# Dictionary where a key (e.g., \"data\") holds the list of dictionaries\n",
    "json_data_with_key = {\n",
    "    \"metadata\": {\n",
    "        \"source\": \"example_data\",\n",
    "        \"version\": \"1.0\"\n",
    "    },\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"name\": \"Charlie\",\n",
    "            \"age\": 35\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Diana\",\n",
    "            \"age\": 28\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n--- JSON Data (Dictionary with 'data' key) ---\")\n",
    "# Using json.dumps for pretty printing\n",
    "print(json.dumps(json_data_with_key, indent=4))\n",
    "print(\"\\nHere, the list of records is accessed via the 'data' key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94018aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why these structures are common for JSON data\n",
    "#===============================================\n",
    "\n",
    "\n",
    "List of Dictionaries (Method 1): Directly maps to a common structure where each object in a JSON array represents a row or record. \n",
    "This is what pd.read_json() often expects by default for simple datasets, or when you create a DataFrame from a list of dicts.\n",
    "Dictionary with a Key (Method 2): Often seen in APIs or larger data files where the core data is nested under a specific key\n",
    "(like \"data\", \"results\", \"items\"), and the top-level dictionary might also contain metadata, pagination info, or other related details. \n",
    "When reading this into Pandas, you'd typically specify the record path (e.g., pd.json_normalize(json_data_with_key, 'data')).\n",
    "Both of these structures are valid ways to represent your \"name\" and \"age\" data in a JSON-like format within Python. \n",
    "The choice depends on the broader context of your data and how you intend to use or exchange it.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e96486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully!\n",
      "\n",
      "--- DataFrame Head (First 5 Rows) ---\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "--- DataFrame Tail (Last 5 Rows) ---\n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "# Accessing csv dataset \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL for the Titanic dataset\n",
    "titanic_dataset_github_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/refs/heads/master/titanic.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "try:\n",
    "    df_titanic = pd.read_csv(titanic_dataset_github_url)\n",
    "    print(\"CSV file loaded successfully!\")\n",
    "\n",
    "    # Display the first 5 rows of the DataFrame (head)\n",
    "    print(\"\\n--- DataFrame Head (First 5 Rows) ---\")\n",
    "    print(df_titanic.head())\n",
    "\n",
    "    # Display the last 5 rows of the DataFrame (tail)\n",
    "    print(\"\\n--- DataFrame Tail (Last 5 Rows) ---\")\n",
    "    print(df_titanic.tail())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    print(\"Please check the URL or your internet connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3592c3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4950999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0              1         0\n",
       "1              2         1\n",
       "2              3         1\n",
       "3              4         1\n",
       "4              5         0\n",
       "..           ...       ...\n",
       "886          887         0\n",
       "887          888         1\n",
       "888          889         0\n",
       "889          890         1\n",
       "890          891         0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13b8b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset loaded successfully!\n",
      "\n",
      "--- Displaying with .loc (Label-based) ---\n",
      "\n",
      "Selected rows 0, 2, 5 and columns 'Name', 'Age', 'Survived' using .loc:\n",
      "                      Name   Age  Survived\n",
      "0  Braund, Mr. Owen Harris  22.0         0\n",
      "2   Heikkinen, Miss. Laina  26.0         1\n",
      "5         Moran, Mr. James   NaN         0\n",
      "\n",
      "Rows from index 10 to 14 (inclusive) and all columns using .loc:\n",
      "    PassengerId  Survived  Pclass                                  Name  \\\n",
      "10           11         1       3       Sandstrom, Miss. Marguerite Rut   \n",
      "11           12         1       1              Bonnell, Miss. Elizabeth   \n",
      "12           13         0       3        Saundercock, Mr. William Henry   \n",
      "13           14         0       3           Andersson, Mr. Anders Johan   \n",
      "14           15         0       3  Vestrom, Miss. Hulda Amanda Adolfina   \n",
      "\n",
      "       Sex   Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
      "10  female   4.0      1      1    PP 9549  16.7000    G6        S  \n",
      "11  female  58.0      0      0     113783  26.5500  C103        S  \n",
      "12    male  20.0      0      0  A/5. 2151   8.0500   NaN        S  \n",
      "13    male  39.0      1      5     347082  31.2750   NaN        S  \n",
      "14  female  14.0      0      0     350406   7.8542   NaN        S  \n",
      "\n",
      "All rows for 'Name', 'Sex', 'Fare' columns using .loc:\n",
      "                                                Name     Sex     Fare\n",
      "0                            Braund, Mr. Owen Harris    male   7.2500\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  71.2833\n",
      "2                             Heikkinen, Miss. Laina  female   7.9250\n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  53.1000\n",
      "4                           Allen, Mr. William Henry    male   8.0500\n",
      "\n",
      "Passengers who survived (first 10) and their Name, Age, Fare using .loc:\n",
      "                                                 Name   Age     Fare\n",
      "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  71.2833\n",
      "2                              Heikkinen, Miss. Laina  26.0   7.9250\n",
      "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  53.1000\n",
      "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  27.0  11.1333\n",
      "9                 Nasser, Mrs. Nicholas (Adele Achem)  14.0  30.0708\n",
      "10                    Sandstrom, Miss. Marguerite Rut   4.0  16.7000\n",
      "11                           Bonnell, Miss. Elizabeth  58.0  26.5500\n",
      "15                   Hewlett, Mrs. (Mary D Kingcome)   55.0  16.0000\n",
      "17                       Williams, Mr. Charles Eugene   NaN  13.0000\n",
      "19                            Masselmani, Mrs. Fatima   NaN   7.2250\n",
      "\n",
      "--- Displaying with .iloc (Integer-location based) ---\n",
      "\n",
      "Selected rows at pos 0, 2, 5 and cols at pos 3, 5, 1 using .iloc:\n",
      "                      Name   Age  Survived\n",
      "0  Braund, Mr. Owen Harris  22.0         0\n",
      "2   Heikkinen, Miss. Laina  26.0         1\n",
      "5         Moran, Mr. James   NaN         0\n",
      "\n",
      "Rows from pos 10-13, Cols from pos 0-3 using .iloc:\n",
      "    PassengerId  Survived  Pclass                             Name\n",
      "10           11         1       3  Sandstrom, Miss. Marguerite Rut\n",
      "11           12         1       1         Bonnell, Miss. Elizabeth\n",
      "12           13         0       3   Saundercock, Mr. William Henry\n",
      "13           14         0       3      Andersson, Mr. Anders Johan\n",
      "\n",
      "All rows for columns at pos 3, 4, 8 using .iloc:\n",
      "                                                Name     Sex            Ticket\n",
      "0                            Braund, Mr. Owen Harris    male         A/5 21171\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female          PC 17599\n",
      "2                             Heikkinen, Miss. Laina  female  STON/O2. 3101282\n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female            113803\n",
      "4                           Allen, Mr. William Henry    male            373450\n",
      "\n",
      "First row using .iloc[0, :]:\n",
      "PassengerId                          1\n",
      "Survived                             0\n",
      "Pclass                               3\n",
      "Name           Braund, Mr. Owen Harris\n",
      "Sex                               male\n",
      "Age                               22.0\n",
      "SibSp                                1\n",
      "Parch                                0\n",
      "Ticket                       A/5 21171\n",
      "Fare                              7.25\n",
      "Cabin                              NaN\n",
      "Embarked                             S\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Last row using .iloc[-1, :]:\n",
      "PassengerId                    891\n",
      "Survived                         0\n",
      "Pclass                           3\n",
      "Name           Dooley, Mr. Patrick\n",
      "Sex                           male\n",
      "Age                           32.0\n",
      "SibSp                            0\n",
      "Parch                            0\n",
      "Ticket                      370376\n",
      "Fare                          7.75\n",
      "Cabin                          NaN\n",
      "Embarked                         Q\n",
      "Name: 890, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the URL for the Titanic dataset\n",
    "titanic_dataset_github_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/refs/heads/master/titanic.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "try:\n",
    "    df_titanic = pd.read_csv(titanic_dataset_github_url)\n",
    "    print(\"Titanic dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    print(\"Please check the URL or your internet connection.\")\n",
    "\n",
    "# --- Displaying with .loc (Label-based) ---\n",
    "print(\"\\n--- Displaying with .loc (Label-based) ---\")\n",
    "\n",
    "# .loc[row_label(s), column_label(s)]\n",
    "\n",
    "# 1. Select specific rows by their index labels and specific columns by their names\n",
    "# Let's pick rows 0, 2, and 5, and columns 'Name', 'Age', 'Survived'.\n",
    "# Note: For this dataset, the default index labels are integers (0, 1, 2, ...).\n",
    "# So, using loc with integer labels is possible, but it's still label-based.\n",
    "print(\"\\nSelected rows 0, 2, 5 and columns 'Name', 'Age', 'Survived' using .loc:\")\n",
    "print(df_titanic.loc[[0, 2, 5], ['Name', 'Age', 'Survived']])\n",
    "\n",
    "# 2. Select a slice of rows and all columns\n",
    "# Remember, .loc slicing is INCLUSIVE of the end label.\n",
    "print(\"\\nRows from index 10 to 14 (inclusive) and all columns using .loc:\")\n",
    "print(df_titanic.loc[10:14, :])\n",
    "\n",
    "# 3. Select all rows for a specific set of columns\n",
    "print(\"\\nAll rows for 'Name', 'Sex', 'Fare' columns using .loc:\")\n",
    "print(df_titanic.loc[:, ['Name', 'Sex', 'Fare']].head()) # Showing head for brevity\n",
    "\n",
    "# 4. Conditional selection with .loc (very common and powerful!)\n",
    "# Select passengers who survived (Survived = 1) and show their 'Name', 'Age', 'Fare'.\n",
    "print(\"\\nPassengers who survived (first 10) and their Name, Age, Fare using .loc:\")\n",
    "print(df_titanic.loc[df_titanic['Survived'] == 1, ['Name', 'Age', 'Fare']].head(10))\n",
    "\n",
    "# --- Displaying with .iloc (Integer-location based) ---\n",
    "print(\"\\n--- Displaying with .iloc (Integer-location based) ---\")\n",
    "\n",
    "# .iloc[row_position(s), column_position(s)]\n",
    "# Remember, .iloc slicing is EXCLUSIVE of the end position.\n",
    "\n",
    "# 1. Select specific rows by their integer positions and specific columns by their integer positions\n",
    "# Let's select rows at positions 0, 2, 5 and columns at positions 3 (Name), 5 (Age), 1 (Survived).\n",
    "print(\"\\nSelected rows at pos 0, 2, 5 and cols at pos 3, 5, 1 using .iloc:\")\n",
    "print(df_titanic.iloc[[0, 2, 5], [3, 5, 1]])\n",
    "\n",
    "# 2. Select a slice of rows and a slice of columns by their integer positions\n",
    "# Rows from position 10 to 14 (exclusive of 14, so positions 10, 11, 12, 13)\n",
    "# Columns from position 0 to 4 (exclusive of 4, so positions 0, 1, 2, 3)\n",
    "print(\"\\nRows from pos 10-13, Cols from pos 0-3 using .iloc:\")\n",
    "print(df_titanic.iloc[10:14, 0:4])\n",
    "\n",
    "# 3. Select all rows and specific columns by their integer positions\n",
    "# Columns 'Name' (pos 3), 'Sex' (pos 4), 'Fare' (pos 8)\n",
    "print(\"\\nAll rows for columns at pos 3, 4, 8 using .iloc:\")\n",
    "print(df_titanic.iloc[:, [3, 4, 8]].head()) # Showing head for brevity\n",
    "\n",
    "# 4. Select the very first row and all columns\n",
    "print(\"\\nFirst row using .iloc[0, :]:\")\n",
    "print(df_titanic.iloc[0, :])\n",
    "\n",
    "# 5. Select the last row and all columns\n",
    "print(\"\\nLast row using .iloc[-1, :]:\")\n",
    "print(df_titanic.iloc[-1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255724d7",
   "metadata": {},
   "source": [
    "# Conditional Indexing and Slicing with dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52879c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Conditional slicing and indexing in Pandas is an incredibly powerful technique that allows you to\n",
    "select rows (and sometimes columns) from your DataFrame or Series based on specific criteria or conditions,\n",
    " rather than just by their labels or positions. It's often referred to as boolean indexing or boolean masking.\n",
    "\n",
    "The core idea is:\n",
    "\n",
    "You create a boolean Series (or array) where True indicates rows (or elements) that meet your condition, \n",
    "and False indicates those that don't.\n",
    "You then use this boolean Series to select the corresponding rows (or elements) from your DataFrame or Series.\n",
    "Let's illustrate with the df_titanic DataFrame.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50064632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:95: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:95: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Byju\\AppData\\Local\\Temp\\ipykernel_64104\\272653710.py:95: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  mr_passengers = df_titanic[df_titanic['Name'].str.contains('Mr\\.', na=False, case=False)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset loaded successfully!\n",
      "\n",
      "Original DataFrame Head:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "--------------------------------------------------\n",
      "\n",
      "--- Passengers older than 30 (All columns) ---\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "1             2         1       1   \n",
      "3             4         1       1   \n",
      "4             5         0       3   \n",
      "6             7         0       1   \n",
      "11           12         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                            Allen, Mr. William Henry    male  35.0      0   \n",
      "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "\n",
      "    Parch    Ticket     Fare Cabin Embarked  \n",
      "1       0  PC 17599  71.2833   C85        C  \n",
      "3       0    113803  53.1000  C123        S  \n",
      "4       0    373450   8.0500   NaN        S  \n",
      "6       0     17463  51.8625   E46        S  \n",
      "11      0    113783  26.5500  C103        S  \n",
      "Number of passengers older than 30: 305\n",
      "\n",
      "--- First-class passengers who survived ---\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "1             2         1       1   \n",
      "3             4         1       1   \n",
      "11           12         1       1   \n",
      "23           24         1       1   \n",
      "31           32         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "23                       Sloper, Mr. William Thompson    male  28.0      0   \n",
      "31     Spencer, Mrs. William Augustus (Marie Eugenie)  female   NaN      1   \n",
      "\n",
      "    Parch    Ticket      Fare Cabin Embarked  \n",
      "1       0  PC 17599   71.2833   C85        C  \n",
      "3       0    113803   53.1000  C123        S  \n",
      "11      0    113783   26.5500  C103        S  \n",
      "23      0    113788   35.5000    A6        S  \n",
      "31      0  PC 17569  146.5208   B78        C  \n",
      "Number of first-class survivors: 136\n",
      "\n",
      "--- Female passengers OR passengers with fare > 100 ---\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n",
      "Number of such passengers: 333\n",
      "\n",
      "--- Using .loc for conditional selection (Survived & Sex) ---\n",
      "                            Name   Age     Fare\n",
      "17  Williams, Mr. Charles Eugene   NaN  13.0000\n",
      "21         Beesley, Mr. Lawrence  34.0  13.0000\n",
      "23  Sloper, Mr. William Thompson  28.0  35.5000\n",
      "36              Mamee, Mr. Hanna   NaN   7.2292\n",
      "55             Woolner, Mr. Hugh   NaN  35.5000\n",
      "Number of male survivors: 109\n",
      "\n",
      "--- Passengers from Pclass 1 or 3 ---\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "Number of passengers in Pclass 1 or 3: 707\n",
      "\n",
      "--- Passengers with Age between 18 and 30 (inclusive) ---\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "0             1         0       3   \n",
      "2             3         1       3   \n",
      "8             9         1       3   \n",
      "12           13         0       3   \n",
      "23           24         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
      "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
      "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
      "23                       Sloper, Mr. William Thompson    male  28.0      0   \n",
      "\n",
      "    Parch            Ticket     Fare Cabin Embarked  \n",
      "0       0         A/5 21171   7.2500   NaN        S  \n",
      "2       0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "8       2            347742  11.1333   NaN        S  \n",
      "12      0         A/5. 2151   8.0500   NaN        S  \n",
      "23      0            113788  35.5000    A6        S  \n",
      "Number of passengers aged 18-30: 296\n",
      "\n",
      "--- Passengers with missing Age ---\n",
      "    PassengerId  Survived  Pclass                           Name     Sex  Age  \\\n",
      "5             6         0       3               Moran, Mr. James    male  NaN   \n",
      "17           18         1       2   Williams, Mr. Charles Eugene    male  NaN   \n",
      "19           20         1       3        Masselmani, Mrs. Fatima  female  NaN   \n",
      "26           27         0       3        Emir, Mr. Farred Chehab    male  NaN   \n",
      "28           29         1       3  O'Dwyer, Miss. Ellen \"Nellie\"  female  NaN   \n",
      "\n",
      "    SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
      "5       0      0  330877   8.4583   NaN        Q  \n",
      "17      0      0  244373  13.0000   NaN        S  \n",
      "19      0      0    2649   7.2250   NaN        C  \n",
      "26      0      0    2631   7.2250   NaN        C  \n",
      "28      0      0  330959   7.8792   NaN        Q  \n",
      "Number of passengers with missing Age: 177\n",
      "\n",
      "--- Passengers whose name contains 'Mr.' (case-insensitive) ---\n",
      "    PassengerId  Survived  Pclass                            Name   Sex   Age  \\\n",
      "0             1         0       3         Braund, Mr. Owen Harris  male  22.0   \n",
      "4             5         0       3        Allen, Mr. William Henry  male  35.0   \n",
      "5             6         0       3                Moran, Mr. James  male   NaN   \n",
      "6             7         0       1         McCarthy, Mr. Timothy J  male  54.0   \n",
      "12           13         0       3  Saundercock, Mr. William Henry  male  20.0   \n",
      "\n",
      "    SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
      "0       1      0  A/5 21171   7.2500   NaN        S  \n",
      "4       0      0     373450   8.0500   NaN        S  \n",
      "5       0      0     330877   8.4583   NaN        Q  \n",
      "6       0      0      17463  51.8625   E46        S  \n",
      "12      0      0  A/5. 2151   8.0500   NaN        S  \n",
      "Number of passengers with 'Mr.' in name: 517\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the URL for the Titanic dataset\n",
    "titanic_dataset_github_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/refs/heads/master/titanic.csv\"\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "try:\n",
    "    df_titanic = pd.read_csv(titanic_dataset_github_url)\n",
    "    print(\"Titanic dataset loaded successfully!\")\n",
    "    print(\"\\nOriginal DataFrame Head:\")\n",
    "    print(df_titanic.head())\n",
    "    print(\"-\" * 50)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    print(\"Please check the URL or your internet connection.\")\n",
    "\n",
    "# --- Conditional Indexing / Slicing ---\n",
    "\n",
    "# 1. Select rows where 'Age' is greater than 30\n",
    "print(\"\\n--- Passengers older than 30 (All columns) ---\")\n",
    "condition_age = df_titanic['Age'] > 30\n",
    "# The 'condition_age' variable is a Series of True/False values:\n",
    "# print(condition_age.head())\n",
    "# Output:\n",
    "# 0    False\n",
    "# 1     True\n",
    "# 2    False\n",
    "# 3     True\n",
    "# 4     True\n",
    "# Name: Age, dtype: bool\n",
    "\n",
    "# Use the boolean Series to filter rows\n",
    "older_passengers = df_titanic[condition_age]\n",
    "# Or more concisely: older_passengers = df_titanic[df_titanic['Age'] > 30]\n",
    "print(older_passengers.head())\n",
    "print(f\"Number of passengers older than 30: {len(older_passengers)}\")\n",
    "\n",
    "# 2. Select rows where 'Survived' is 1 (meaning survived) AND 'Pclass' is 1 (first class)\n",
    "print(\"\\n--- First-class passengers who survived ---\")\n",
    "condition_survived = df_titanic['Survived'] == 1\n",
    "condition_pclass = df_titanic['Pclass'] == 1\n",
    "\n",
    "# Combine conditions using '&' (logical AND)\n",
    "# Remember to wrap individual conditions in parentheses due to operator precedence\n",
    "first_class_survivors = df_titanic[condition_survived & condition_pclass]\n",
    "# Or: first_class_survivors = df_titanic[(df_titanic['Survived'] == 1) & (df_titanic['Pclass'] == 1)]\n",
    "print(first_class_survivors.head())\n",
    "print(f\"Number of first-class survivors: {len(first_class_survivors)}\")\n",
    "\n",
    "# 3. Select rows where 'Sex' is 'female' OR 'Fare' is greater than 100\n",
    "print(\"\\n--- Female passengers OR passengers with fare > 100 ---\")\n",
    "condition_female = df_titanic['Sex'] == 'female'\n",
    "condition_fare = df_titanic['Fare'] > 100\n",
    "\n",
    "# Combine conditions using '|' (logical OR)\n",
    "females_or_high_fare = df_titanic[condition_female | condition_fare]\n",
    "print(females_or_high_fare.head())\n",
    "print(f\"Number of such passengers: {len(females_or_high_fare)}\")\n",
    "\n",
    "# 4. Using .loc for conditional selection with specific columns\n",
    "# This is generally the recommended way for readability and performance\n",
    "print(\"\\n--- Using .loc for conditional selection (Survived & Sex) ---\")\n",
    "# Select name, age, and fare for male survivors\n",
    "male_survivors_data = df_titanic.loc[(df_titanic['Survived'] == 1) & (df_titanic['Sex'] == 'male'),\n",
    "                                     ['Name', 'Age', 'Fare']]\n",
    "print(male_survivors_data.head())\n",
    "print(f\"Number of male survivors: {len(male_survivors_data)}\")\n",
    "\n",
    "# 5. Using .isin() for multiple discrete values\n",
    "print(\"\\n--- Passengers from Pclass 1 or 3 ---\")\n",
    "# Select passengers from Pclass 1 or 3\n",
    "pclass_filter = df_titanic['Pclass'].isin([1, 3])\n",
    "pclass_1_or_3_passengers = df_titanic[pclass_filter]\n",
    "print(pclass_1_or_3_passengers.head())\n",
    "print(f\"Number of passengers in Pclass 1 or 3: {len(pclass_1_or_3_passengers)}\")\n",
    "\n",
    "# 6. Using .between() for numerical ranges\n",
    "print(\"\\n--- Passengers with Age between 18 and 30 (inclusive) ---\")\n",
    "age_range_filter = df_titanic['Age'].between(18, 30, inclusive='both')\n",
    "age_18_to_30_passengers = df_titanic[age_range_filter]\n",
    "print(age_18_to_30_passengers.head())\n",
    "print(f\"Number of passengers aged 18-30: {len(age_18_to_30_passengers)}\")\n",
    "\n",
    "# 7. Selecting rows with missing values (e.g., missing Age)\n",
    "print(\"\\n--- Passengers with missing Age ---\")\n",
    "missing_age_passengers = df_titanic[df_titanic['Age'].isnull()]\n",
    "print(missing_age_passengers.head())\n",
    "print(f\"Number of passengers with missing Age: {len(missing_age_passengers)}\")\n",
    "\n",
    "# 8. Selecting rows where a string column contains a specific substring\n",
    "print(\"\\n--- Passengers whose name contains 'Mr.' (case-insensitive) ---\")\n",
    "# Make sure the 'Name' column is of string type and handle potential NaNs\n",
    "# .str accessor is used for string methods on Series\n",
    "# .fillna('') is used to treat NaN names as empty strings for the contains check\n",
    "mr_passengers = df_titanic[df_titanic['Name'].str.contains('Mr\\.', na=False, case=False)]\n",
    "print(mr_passengers.head())\n",
    "print(f\"Number of passengers with 'Mr.' in name: {len(mr_passengers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8e952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a181e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
